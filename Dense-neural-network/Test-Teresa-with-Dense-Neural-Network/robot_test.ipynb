{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the testing of the Teresa Robot\n",
    "## Importing all necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EJt__rjLgh_P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saadubuntu/Documents/Teresa_robot_internship_2021/venv/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import roslibpy # Communication with the HMI\n",
    "import time \n",
    "from src.gym_envs.RobotEnv_ import RobotEnv # Training environment\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import roslibpy # API of ROS\n",
    "from src.robots.Teresa_adap import Teresa # This is the representation of Teresa Robot\n",
    "from src.utils.training_tools import NB_STATES\n",
    "from src.robots.actions.camera_adap import DlinkDCSCamera # class for the camera\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "import cv2\n",
    "import logging\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tests.FormulaTests import FormulaTests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the connection with ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Bha-MkJ-gjKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#ip_ordi : 192.168.1.50\n",
    "\n",
    "client = roslibpy.Ros(host=\"192.168.1.14\", port=9090)\n",
    "client.run()\n",
    "print(client.is_connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the connection with the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DayNightMode': '2',\n",
       " 'LightSensorControl': '3',\n",
       " 'IRLedScheduleSunStart': '00:00',\n",
       " 'IRLedScheduleSunEnd': '00:00',\n",
       " 'IRLedScheduleMonStart': '00:00',\n",
       " 'IRLedScheduleMonEnd': '00:00',\n",
       " 'IRLedScheduleTueStart': '00:00',\n",
       " 'IRLedScheduleTueEnd': '00:00',\n",
       " 'IRLedScheduleWedStart': '00:00',\n",
       " 'IRLedScheduleWedEnd': '00:00',\n",
       " 'IRLedScheduleThuStart': '00:00',\n",
       " 'IRLedScheduleThuEnd': '00:00',\n",
       " 'IRLedScheduleFriStart': '00:00',\n",
       " 'IRLedScheduleFriEnd': '00:00',\n",
       " 'IRLedScheduleSatStart': '00:00',\n",
       " 'IRLedScheduleSatEnd': '00:00'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host='192.168.1.35'\n",
    "user='admin'\n",
    "password='123456'\n",
    "camera = DlinkDCSCamera(host = host, user = user, password = password)\n",
    "camera.set_day_night(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the robot from the jupyternotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): 0\n",
      "{'angular': {'z': 0.778}}\n",
      "[[519 260  23  46]]\n",
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): 3\n",
      "{'linear': {'x': 0.5}}\n",
      "[[376 196  51  51]]\n",
      "Centered\n",
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): exit\n"
     ]
    }
   ],
   "source": [
    "client.run()\n",
    "teresa_controller = Teresa(client)\n",
    "env = RobotEnv(teresa_controller, client)\n",
    "\n",
    "env.reset()\n",
    "finish = False\n",
    "\n",
    "while not finish:\n",
    "    movement = input('Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): ')\n",
    "    if movement == 'exit':\n",
    "        finish = True\n",
    "        continue\n",
    "    movement = int(movement)\n",
    "    state, reward, done, _ = env.step(movement)\n",
    "    if done and reward:\n",
    "        print(\"Centered\")\n",
    "        #env.reset()\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING the camera output to adjust the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angular': {'z': 0.778}}\n",
      "[[ 44 712  32  64]]\n",
      "{'angular': {'z': -0.778}}\n",
      "[[337 184  51  51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run() # This run the main loop of ROS\n",
    "teresa_controller = Teresa(client) # Robot API\n",
    "env = RobotEnv(teresa_controller, client) # Training Environment\n",
    "\n",
    "\n",
    "action=0\n",
    "env.step(action)\n",
    "env.render()\n",
    "env.step(1)\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration of the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.training_tools import OBSERVATION_FILE, IMAGE_SIZE, SQUARE_SIZE_X, SQUARE_SIZE_Y, STEP_X, STEP_Y, ERROR, FINAL_X, FINAL_Y\n",
    "\n",
    "def calibration():\n",
    "    # put the robot in front the person in any position you want\n",
    "    #this function will center the camera of the robot on the person\n",
    "    env.step(0)\n",
    "    env.render()\n",
    "    face_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, c_done = define_rectangles(face_cascade)\n",
    "    \n",
    "    \n",
    "    if (x_1 + y_1 + x_2 + y_2 + x_desired + y_desired + w_desired + h_desired)== 0:\n",
    "        print('person not detected')\n",
    "    else:\n",
    "        #(0 Right, 1 Left, 2 Backward, 3 Forward)\n",
    "        while c_done:\n",
    "            #condition the robot is too much on the right\n",
    "            while (x_desired > x_1):\n",
    "                print('right')#regrding the robot, the robot will turn left\n",
    "                env.step(0)\n",
    "                env.render()\n",
    "                x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, c_done = define_rectangles(face_cascade)\n",
    "            #condition the robot is too much on the left\n",
    "            while (x_desired+w_desired < x_2):\n",
    "                print('left')\n",
    "                env.step(1)\n",
    "                env.render()\n",
    "                x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired,c_done = define_rectangles( face_cascade)\n",
    "            #condition on the top and the bottom of the rectangle\n",
    "            while ((y_desired > y_1) or (y_desired+h_desired < y_2)):\n",
    "                print('backward')\n",
    "                env.step(2)\n",
    "                env.render()\n",
    "                x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, c_done = define_rectangles(face_cascade)\n",
    "            if (x_desired < x_1) and (x_desired+w_desired > x_2) and ((y_desired < y_1) or (y_desired+h_desired > y_2)):\n",
    "                c_done=False\n",
    "                print('finish')\n",
    "    \n",
    "def define_rectangles(face_cascade):\n",
    "    image = cv2.imread('env_observation.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    object_locations=face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(object_locations)>0:\n",
    "        x, y, w, h = object_locations[0]\n",
    "        x_1 = x-w #top left of the rectangle\n",
    "        y_1 = y-h #top left of the rectangle\n",
    "        x_2 = x+2*w #bottom right of the rectangle\n",
    "        y_2 = y+8*h #bottom rigth of the rectangle\n",
    "        \n",
    "        x_desired,y_desired = FINAL_X, FINAL_Y # 70 added for the wanted rectangle to be a bit lower\n",
    "        w_desired = SQUARE_SIZE_X\n",
    "        h_desired = SQUARE_SIZE_Y\n",
    "        cv2.rectangle(image,(x_1,y_1),(x_2,y_2),(255,0,0),2)\n",
    "        cv2.rectangle(image, (x_desired, y_desired), (x_desired+w_desired, y_desired+h_desired), (25, 125, 225), 5)\n",
    "\n",
    "        cv2.imshow('image', image)\n",
    "        cv2.waitKey(1)\n",
    "        return x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, True\n",
    "    else:\n",
    "        print('person not detected')\n",
    "        env.render()\n",
    "        return 0,0,0,0,0,0,0,0, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the commands sent to the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angular': {'z': -0.75}}\n"
     ]
    }
   ],
   "source": [
    "import roslibpy\n",
    "import time\n",
    "\n",
    "from src.utils.training_tools import EXECUTION_TIME\n",
    "\n",
    "STOP_ROBOT = {\n",
    "    'linear': {\n",
    "        'y': 0.0, \n",
    "        'x': 0.0, \n",
    "        'z': 0.0\n",
    "    }, \n",
    "    'angular': {\n",
    "        'y': 0.0, \n",
    "        'x': 0.0, \n",
    "        'z': 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "Publish the move to the ros topic to execute it\n",
    "'''\n",
    "def execute_move(move_msg, move_topic):\n",
    "    #move_msg = movements[move] # Get the ROS message for the move selected\n",
    "    print(move_msg)\n",
    "    # Execute the move\n",
    "    move_topic.publish(roslibpy.Message(move_msg))\n",
    "    time.sleep(EXECUTION_TIME)\n",
    "    move_topic.publish(roslibpy.Message(STOP_ROBOT))\n",
    "    time.sleep(EXECUTION_TIME)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "Test\n",
    "'''\n",
    "# NB: for a rotation of 0.5 the robot doesn't turn around 0.75 seems to be a good value\n",
    "move_topic = {\n",
    "        'topic_name': '/cmd_vel',\n",
    "        'msg_type': 'geometry_msgs/Twist'\n",
    "    }\n",
    "move_topic = roslibpy.Topic(client, move_topic['topic_name'], move_topic['msg_type'])\n",
    "move_msg={'angular': {'z': -0.75}} # change this line to test oder command\n",
    "\n",
    "execute_move(move_msg, move_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the haarcasaced filter on images\n",
    "(the filter don't have an sufficiently high accuracy for reinforcement learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FINAL_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c5cc4b74b50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_color\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mx_desired\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_desired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFINAL_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFINAL_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mw_desired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQUARE_SIZE_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mh_desired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQUARE_SIZE_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FINAL_X' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "body_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_fullbody.xml')\n",
    "\n",
    "img = cv2.imread('env_observation.jpg') #enter the file name to test\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "body=body_cascade.detectMultiScale(gray,1.2,3)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x-w,y-h),(x+2*w,y+11*h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "x_desired,y_desired = FINAL_X, FINAL_Y\n",
    "w_desired = SQUARE_SIZE_X\n",
    "h_desired = SQUARE_SIZE_Y\n",
    "\n",
    "cv2.rectangle(img, (x_desired, y_desired), (x_desired+w_desired, y_desired+h_desired), (25, 125, 225), 5)\n",
    "\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "#type 0 to quit the window\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-b374cf08b167>:51: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/saadubuntu/Documents/Teresa_robot_internship_2021/venv/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "NbStat = NB_STATES\n",
    "state_size = NbStat\n",
    "action_size = 4\n",
    "# new_graph = tf.Graph()\n",
    "initializer=tf.initializers.glorot_uniform()\n",
    "learning_rate = 0.01\n",
    "\n",
    "def discount_correct_rewards(r, gamma=0.99):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    #if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "\n",
    "  discounted_r -= discounted_r.mean()\n",
    "  discounted_r /- discounted_r.std()\n",
    "  return discounted_r\n",
    "\n",
    "def discount_and_normalize_rewards(episode_rewards):\n",
    "    discounted_episode_rewards = np.zeros_like(episode_rewards)\n",
    "    cumulative = 0.0\n",
    "    #print(\"len episode rewards\",episode_rewards)\n",
    "    for i in reversed(range(len(episode_rewards))):\n",
    "        cumulative = cumulative * gamma + episode_rewards[i]\n",
    "        #print(\"dans boucle\",episode_rewards[i],\"cyl\",cumulative)\n",
    "        discounted_episode_rewards[i] = cumulative\n",
    "    \n",
    "    mean = np.mean(discounted_episode_rewards)\n",
    "    std = np.std(discounted_episode_rewards)\n",
    "    if std :\n",
    "        discounted_episode_rewards = (discounted_episode_rewards - mean) / (std)\n",
    "    else:\n",
    "        discounted_episode=[]\n",
    "        discounted_episode_rewards[0] = np.array(mean)\n",
    "        print(\"ATTTTTTTTTTTTTTTTTT\")\n",
    "    #print(\"dis\",discounted_episode_rewards,\"std\",std)\n",
    "    \n",
    "    return discounted_episode_rewards\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_ = tf.placeholder(tf.float32, [None, state_size], name=\"input_\")\n",
    "    actions = tf.placeholder(tf.int32, [None, action_size], name=\"actions\")\n",
    "    discounted_episode_rewards_ = tf.placeholder(tf.float32, [None,], name=\"discounted_episode_rewards\")\n",
    "    \n",
    "    # Add this placeholder for having this variable in tensorboard\n",
    "    mean_reward_ = tf.placeholder(tf.float32 , name=\"mean_reward\")\n",
    "\n",
    "    with tf.name_scope(\"fc1\"):\n",
    "        fc1 = tf.layers.dense(input_ , 20, activation=tf.nn.relu,kernel_initializer=initializer)\n",
    "\n",
    "    with tf.name_scope(\"fc2\"):\n",
    "        fc2 = tf.layers.dense(fc1, action_size,activation= tf.nn.relu, kernel_initializer=initializer)\n",
    "    \n",
    "    with tf.name_scope(\"fc3\"):\n",
    "        fc3 = tf.layers.dense(fc2, action_size, activation= None,kernel_initializer=initializer)\n",
    "\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        action_distribution = tf.nn.softmax(fc3)\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        # tf.nn.softmax_cross_entropy_with_logits computes the cross entropy of the result after applying the softmax function\n",
    "        # If you have single-class labels, where an object can only belong to one class, you might now consider using \n",
    "        # tf.nn.sparse_softmax_cross_entropy_with_logits so that you don't have to convert your labels to a dense one-hot array. \n",
    "        neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits = fc3, labels = actions)\n",
    "        #loss = tf.nn.sparse_softmax_cross_entropy_with_logits (neg_log_prob * discounted_episode_rewards_)\n",
    "        loss = tf.reduce_mean(neg_log_prob * discounted_episode_rewards_) \n",
    "        \n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "# Setup TensorBoard Writer\n",
    "\n",
    "\n",
    "## Losses\n",
    "## TRAINING Hyperparameters\n",
    "\n",
    "# tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "# ## Reward mean\n",
    "# tf.summary.scalar(\"Reward_mean\", mean_reward_)\n",
    "\n",
    "max_episodes = 500\n",
    "\n",
    "gamma = 0.95 # Discount rate\n",
    "max_batch = NbStat*5\n",
    "    \n",
    "episode_rewards_sum = 0\n",
    "\n",
    "        # Launch the game\n",
    "    #state = env.reset()\n",
    "    #ne_state=np.identity(NbStat)[state:state+1]\n",
    "    #env.render()\n",
    "episode_length=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from pgpendul.ckpt\n",
      "None\n",
      "****************************************************\n",
      "EPISODE  0\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[308 176  50  50]]\n",
      "state 0 ne_state 2016 action 3\n",
      "Score 1\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'angular': {'z': -0.778}}\n",
      "[[160 157  52  52]]\n",
      "state 0 ne_state 1757 action 1\n",
      "[[0.2541288  0.24532402 0.24917848 0.2513687 ]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[178 169  50  50]\n",
      " [629 212  52  52]]\n",
      "state 1757 ne_state 1875 action 2\n",
      "[[0.25623852 0.24780703 0.25260502 0.24334939]]\n",
      "{'angular': {'z': -0.778}}\n",
      "[[117 166  49  49]]\n",
      "state 1875 ne_state 1863 action 1\n",
      "[[0.255789   0.24721444 0.24684177 0.2501547 ]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[113 175  47  47]]\n",
      "state 1863 ne_state 1977 action 2\n",
      "[[0.25496715 0.24492182 0.25335503 0.24675599]]\n",
      "{'angular': {'z': -0.778}}\n",
      "[[ 86 165  48  48]]\n",
      "state 1977 ne_state 1857 action 1\n",
      "[[0.2545836  0.2480021  0.24799491 0.2494194 ]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[ 40 158  50  50]]\n",
      "state 1857 ne_state 1733 action 3\n",
      "[[0.25371552 0.2471796  0.2513179  0.24778709]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 1733 ne_state 0 action 3\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'angular': {'z': -0.778}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'angular': {'z': 0.778}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.2573676  0.24735928 0.2543879  0.2408852 ]]\n",
      "{'angular': {'z': 0.778}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e1efa7ab67ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# new_state, reward, done, info = env.step(int(action),True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repo_final/Teresa_robot_internship_2021/Dense-neural-network/Test-Teresa-with-Dense-Neural-Network/src/gym_envs/RobotEnv_.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# Boolean that indicates that an episode has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_robot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Execute Move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Process image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mobject_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Define state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repo_final/Teresa_robot_internship_2021/Dense-neural-network/Test-Teresa-with-Dense-Neural-Network/src/robots/Robot_adap.py\u001b[0m in \u001b[0;36mmove_robot\u001b[0;34m(self, move)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mmovements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mexecute_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtake_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repo_final/Teresa_robot_internship_2021/Dense-neural-network/Test-Teresa-with-Dense-Neural-Network/src/robots/actions/move_adap.py\u001b[0m in \u001b[0;36mexecute_move\u001b[0;34m(move_msg, move_topic)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Execute the move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmove_topic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroslibpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXECUTION_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mmove_topic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroslibpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP_ROBOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXECUTION_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "client.run() # This run the main loop of ROS\n",
    "teresa_controller = Teresa(client) # Robot API\n",
    "env = RobotEnv(teresa_controller, client) # Training Environment\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "        # Load the model\n",
    "    print(saver.restore(sess, \"pgpendul.ckpt\"))\n",
    "    # if not saver.restore(sess, \"pgpendul.ckpt\"):\n",
    "    #     print()\n",
    "    total_rewards = 0\n",
    "    rewards = []\n",
    "\n",
    "    for episode in range(100):\n",
    "        state = env.reset()\n",
    "        #ne_state=np.identity(NbStat)[state:state+1]\n",
    "        step = 0\n",
    "        done = False\n",
    "        \n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "\n",
    "       \n",
    "        #while True:\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < 10:\n",
    "            j+=1\n",
    "            state=int(state)\n",
    "            ne_state=np.identity(NbStat)[state:state+1]\n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT, WE'RE OUTPUT PROBABILITIES.\n",
    "            action_probability_distribution = sess.run(action_distribution, feed_dict={input_: ne_state.reshape([1,NbStat])})\n",
    "            print(action_probability_distribution)\n",
    "            action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
    "            #action = np.argmax(action_probability_distribution)\n",
    "            \n",
    "            \n",
    "            # new_state, reward, done, info = env.step(int(action),True)\n",
    "            new_state, reward, done, info = env.step(int(action))\n",
    "            env.render()\n",
    "\n",
    "            print(\"state\",state,\"ne_state\",new_state,\"action\",action) \n",
    "            total_rewards += reward\n",
    "            if done:    \n",
    "                rewards.append(total_rewards)\n",
    "                print (\"Score\", total_rewards)\n",
    "                break\n",
    "            state = new_state\n",
    "    env.close()\n",
    "print (\"Score over time: \" ,  total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the rewards according to the episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "robot_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
