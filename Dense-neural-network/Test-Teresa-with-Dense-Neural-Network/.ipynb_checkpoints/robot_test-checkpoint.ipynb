{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the testing of the Teresa Robot\n",
    "## Importing all necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EJt__rjLgh_P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: UserWarning: You do not have a working installation of the service_identity module: 'No module named 'service_identity''.  Please install it from <https://pypi.python.org/pypi/service_identity> and make sure all of its dependencies are satisfied.  Without the service_identity module, Twisted can perform only rudimentary TLS client hostname verification.  Many valid certificate/hostname mappings may be rejected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saadubuntu/Documents/robot_controller/venv/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import roslibpy # Communication with the HMI\n",
    "import time \n",
    "from src.gym_envs.RobotEnv_ import RobotEnv # Training environment\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import roslibpy # API of ROS\n",
    "from src.robots.Teresa_adap import Teresa # This is the representation of Teresa Robot\n",
    "from src.utils.training_tools import NB_STATES\n",
    "from src.robots.actions.camera_adap import DlinkDCSCamera # class for the camera\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "import cv2\n",
    "import logging\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tests.FormulaTests import FormulaTests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the connection with ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Bha-MkJ-gjKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#ip_ordi : 192.168.1.50\n",
    "\n",
    "client = roslibpy.Ros(host=\"192.168.1.14\", port=9090)\n",
    "client.run()\n",
    "print(client.is_connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the connection with the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DayNightMode': '2',\n",
       " 'LightSensorControl': '3',\n",
       " 'IRLedScheduleSunStart': '00:00',\n",
       " 'IRLedScheduleSunEnd': '00:00',\n",
       " 'IRLedScheduleMonStart': '00:00',\n",
       " 'IRLedScheduleMonEnd': '00:00',\n",
       " 'IRLedScheduleTueStart': '00:00',\n",
       " 'IRLedScheduleTueEnd': '00:00',\n",
       " 'IRLedScheduleWedStart': '00:00',\n",
       " 'IRLedScheduleWedEnd': '00:00',\n",
       " 'IRLedScheduleThuStart': '00:00',\n",
       " 'IRLedScheduleThuEnd': '00:00',\n",
       " 'IRLedScheduleFriStart': '00:00',\n",
       " 'IRLedScheduleFriEnd': '00:00',\n",
       " 'IRLedScheduleSatStart': '00:00',\n",
       " 'IRLedScheduleSatEnd': '00:00'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host='192.168.1.35'\n",
    "user='admin'\n",
    "password='123456'\n",
    "camera = DlinkDCSCamera(host = host, user = user, password = password)\n",
    "camera.set_day_night(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the robot from the jupyternotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): 0\n",
      "{'angular': {'z': 0.778}}\n",
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): 1\n",
      "{'angular': {'z': -0.778}}\n",
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): 1\n",
      "{'angular': {'z': -0.778}}\n",
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): 1\n",
      "{'angular': {'z': -0.778}}\n",
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): 1\n",
      "{'angular': {'z': -0.778}}\n",
      "Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): exit\n"
     ]
    }
   ],
   "source": [
    "client.run()\n",
    "teresa_controller = Teresa(client)\n",
    "env = RobotEnv(teresa_controller, client)\n",
    "\n",
    "env.reset()\n",
    "finish = False\n",
    "\n",
    "while not finish:\n",
    "    movement = input('Enter a movement (0 Right, 1 Left, 2 Backward, 3 Forward, exit): ')\n",
    "    if movement == 'exit':\n",
    "        finish = True\n",
    "        continue\n",
    "    movement = int(movement)\n",
    "    state, reward, done, _ = env.step(movement)\n",
    "    if done and reward:\n",
    "        print(\"Centered\")\n",
    "        #env.reset()\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING the camera output to adjust the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angular': {'z': 0.778}}\n",
      "{'angular': {'z': -0.778}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run() # This run the main loop of ROS\n",
    "teresa_controller = Teresa(client) # Robot API\n",
    "env = RobotEnv(teresa_controller, client) # Training Environment\n",
    "\n",
    "\n",
    "action=0\n",
    "env.step(action)\n",
    "env.render()\n",
    "env.step(1)\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration of the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.training_tools import OBSERVATION_FILE, IMAGE_SIZE, SQUARE_SIZE_X, SQUARE_SIZE_Y, STEP_X, STEP_Y, ERROR, FINAL_X, FINAL_Y\n",
    "\n",
    "def calibration():\n",
    "    # put the robot in front the person in any position you want\n",
    "    #this function will center the camera of the robot on the person\n",
    "    env.step(0)\n",
    "    env.render()\n",
    "    face_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, c_done = define_rectangles(face_cascade)\n",
    "    \n",
    "    \n",
    "    if (x_1 + y_1 + x_2 + y_2 + x_desired + y_desired + w_desired + h_desired)== 0:\n",
    "        print('person not detected')\n",
    "    else:\n",
    "        #(0 Right, 1 Left, 2 Backward, 3 Forward)\n",
    "        while c_done:\n",
    "            #condition the robot is too much on the right\n",
    "            while (x_desired+w_desired > x_1):\n",
    "                print('right')#regrding the robot, the robot will turn left\n",
    "                env.step(0)\n",
    "                env.render()\n",
    "                x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, c_done = define_rectangles(face_cascade)\n",
    "            #condition the robot is too much on the left\n",
    "            while (x_desired+w_desired < x_2):\n",
    "                print('left')\n",
    "                env.step(1)\n",
    "                env.render()\n",
    "                x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired,c_done = define_rectangles( face_cascade)\n",
    "            #condition on the top and the bottom of the rectangle\n",
    "            while ((y_desired > y_1) or (y_desired+h_desired < y_2)):\n",
    "                print('backward')\n",
    "                env.step(2)\n",
    "                env.render()\n",
    "                    x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, c_done = define_rectangles(face_cascade)\n",
    "            if (x_desired < x_1) and (x_desired+w_desired > x_2) and ((y_desired < y_1) or (y_desired+h_desired > y_2)):\n",
    "                c_done=False\n",
    "                print('finish')\n",
    "    \n",
    "def define_rectangles(face_cascade):\n",
    "    image = cv2.imread('env_observation.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    object_locations=face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(object_locations)>0:\n",
    "        x, y, w, h = object_locations[0]\n",
    "        x_1 = x-w #top left of the rectangle\n",
    "        y_1 = y-h #top left of the rectangle\n",
    "        x_2 = x+2*w #bottom right of the rectangle\n",
    "        y_2 = y+8*h #bottom rigth of the rectangle\n",
    "        \n",
    "        x_desired,y_desired = FINAL_X, FINAL_Y # 70 added for the wanted rectangle to be a bit lower\n",
    "        w_desired = SQUARE_SIZE_X\n",
    "        h_desired = SQUARE_SIZE_Y\n",
    "        cv2.rectangle(image,(x_1,y_1),(x_2,y_2),(255,0,0),2)\n",
    "        cv2.rectangle(image, (x_desired, y_desired), (x_desired+w_desired, y_desired+h_desired), (25, 125, 225), 5)\n",
    "\n",
    "        cv2.imshow('image', image)\n",
    "        cv2.waitKey(1)\n",
    "        return x_1, y_1, x_2, y_2, x_desired, y_desired, w_desired, h_desired, True\n",
    "    else:\n",
    "        print('person not detected')\n",
    "        env.render()\n",
    "        return 0,0,0,0,0,0,0,0, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angular': {'z': 0.778}}\n",
      "[[348 190  49  49]]\n",
      "ok\n",
      "backward\n",
      "{'linear': {'x': -0.5}}\n",
      "[[311 145  72 144]]\n",
      "ok\n",
      "right\n",
      "{'angular': {'z': 0.778}}\n",
      "[[567 220  45  45]]\n",
      "ok\n",
      "left\n",
      "{'angular': {'z': -0.778}}\n",
      "[[455 211  46  46]]\n",
      "ok\n",
      "left\n",
      "{'angular': {'z': -0.778}}\n",
      "[[267 196  46  46]]\n",
      "ok\n",
      "backward\n",
      "{'linear': {'x': -0.5}}\n",
      "[[250 201  45  45]]\n",
      "ok\n",
      "right\n",
      "{'angular': {'z': 0.778}}\n",
      "[[327 206  45  45]]\n",
      "ok\n",
      "right\n",
      "{'angular': {'z': 0.778}}\n",
      "[[385 210  45  45]]\n",
      "ok\n",
      "right\n",
      "{'angular': {'z': 0.778}}\n",
      "[[462 165  75 150]\n",
      " [230 707  32  64]]\n",
      "ok\n",
      "right\n",
      "{'angular': {'z': 0.778}}\n",
      "[[576 223  44  44]]\n",
      "ok\n",
      "left\n",
      "{'angular': {'z': -0.778}}\n",
      "[[484 218  46  46]]\n",
      "ok\n",
      "left\n",
      "{'angular': {'z': -0.778}}\n",
      "[[389 209  45  45]]\n",
      "ok\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the commands sent to the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angular': {'z': -0.75}}\n"
     ]
    }
   ],
   "source": [
    "import roslibpy\n",
    "import time\n",
    "\n",
    "from src.utils.training_tools import EXECUTION_TIME\n",
    "\n",
    "STOP_ROBOT = {\n",
    "    'linear': {\n",
    "        'y': 0.0, \n",
    "        'x': 0.0, \n",
    "        'z': 0.0\n",
    "    }, \n",
    "    'angular': {\n",
    "        'y': 0.0, \n",
    "        'x': 0.0, \n",
    "        'z': 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "'''\n",
    "Publish the move to the ros topic to execute it\n",
    "'''\n",
    "def execute_move(move_msg, move_topic):\n",
    "    #move_msg = movements[move] # Get the ROS message for the move selected\n",
    "    print(move_msg)\n",
    "    # Execute the move\n",
    "    move_topic.publish(roslibpy.Message(move_msg))\n",
    "    time.sleep(EXECUTION_TIME)\n",
    "    move_topic.publish(roslibpy.Message(STOP_ROBOT))\n",
    "    time.sleep(EXECUTION_TIME)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "Test\n",
    "'''\n",
    "# NB: for a rotation of 0.5 the robot doesn't turn around 0.75 seems to be a good value\n",
    "move_topic = {\n",
    "        'topic_name': '/cmd_vel',\n",
    "        'msg_type': 'geometry_msgs/Twist'\n",
    "    }\n",
    "move_topic = roslibpy.Topic(client, move_topic['topic_name'], move_topic['msg_type'])\n",
    "move_msg={'angular': {'z': -0.75}} # change this line to test oder command\n",
    "\n",
    "execute_move(move_msg, move_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the haarcasaced filter on images\n",
    "(the filter don't have an sufficiently high accuracy for reinforcement learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_eye.xml')\n",
    "body_cascade = cv2.CascadeClassifier('Haarcascades/haarcascade_fullbody.xml')\n",
    "\n",
    "img = cv2.imread('env_observation3.jpg') #enter the file name to test\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "body=body_cascade.detectMultiScale(gray,1.2,3)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x-w,y-h),(x+2*w,y+11*h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "x_desired,y_desired = FINAL_X, FINAL_Y\n",
    "w_desired = SQUARE_SIZE_X\n",
    "h_desired = SQUARE_SIZE_Y\n",
    "\n",
    "cv2.rectangle(img, (x_desired, y_desired), (x_desired+w_desired, y_desired+h_desired), (25, 125, 225), 5)\n",
    "\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "#type 0 to quit the window\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[370,  82,  62,  62]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-b374cf08b167>:51: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/saadubuntu/Documents/robot_controller/venv/lib/python3.6/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "NbStat = NB_STATES\n",
    "state_size = NbStat\n",
    "action_size = 4\n",
    "# new_graph = tf.Graph()\n",
    "initializer=tf.initializers.glorot_uniform()\n",
    "learning_rate = 0.01\n",
    "\n",
    "def discount_correct_rewards(r, gamma=0.99):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    #if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "\n",
    "  discounted_r -= discounted_r.mean()\n",
    "  discounted_r /- discounted_r.std()\n",
    "  return discounted_r\n",
    "\n",
    "def discount_and_normalize_rewards(episode_rewards):\n",
    "    discounted_episode_rewards = np.zeros_like(episode_rewards)\n",
    "    cumulative = 0.0\n",
    "    #print(\"len episode rewards\",episode_rewards)\n",
    "    for i in reversed(range(len(episode_rewards))):\n",
    "        cumulative = cumulative * gamma + episode_rewards[i]\n",
    "        #print(\"dans boucle\",episode_rewards[i],\"cyl\",cumulative)\n",
    "        discounted_episode_rewards[i] = cumulative\n",
    "    \n",
    "    mean = np.mean(discounted_episode_rewards)\n",
    "    std = np.std(discounted_episode_rewards)\n",
    "    if std :\n",
    "        discounted_episode_rewards = (discounted_episode_rewards - mean) / (std)\n",
    "    else:\n",
    "        discounted_episode=[]\n",
    "        discounted_episode_rewards[0] = np.array(mean)\n",
    "        print(\"ATTTTTTTTTTTTTTTTTT\")\n",
    "    #print(\"dis\",discounted_episode_rewards,\"std\",std)\n",
    "    \n",
    "    return discounted_episode_rewards\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_ = tf.placeholder(tf.float32, [None, state_size], name=\"input_\")\n",
    "    actions = tf.placeholder(tf.int32, [None, action_size], name=\"actions\")\n",
    "    discounted_episode_rewards_ = tf.placeholder(tf.float32, [None,], name=\"discounted_episode_rewards\")\n",
    "    \n",
    "    # Add this placeholder for having this variable in tensorboard\n",
    "    mean_reward_ = tf.placeholder(tf.float32 , name=\"mean_reward\")\n",
    "\n",
    "    with tf.name_scope(\"fc1\"):\n",
    "        fc1 = tf.layers.dense(input_ , 20, activation=tf.nn.relu,kernel_initializer=initializer)\n",
    "\n",
    "    with tf.name_scope(\"fc2\"):\n",
    "        fc2 = tf.layers.dense(fc1, action_size,activation= tf.nn.relu, kernel_initializer=initializer)\n",
    "    \n",
    "    with tf.name_scope(\"fc3\"):\n",
    "        fc3 = tf.layers.dense(fc2, action_size, activation= None,kernel_initializer=initializer)\n",
    "\n",
    "    with tf.name_scope(\"softmax\"):\n",
    "        action_distribution = tf.nn.softmax(fc3)\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        # tf.nn.softmax_cross_entropy_with_logits computes the cross entropy of the result after applying the softmax function\n",
    "        # If you have single-class labels, where an object can only belong to one class, you might now consider using \n",
    "        # tf.nn.sparse_softmax_cross_entropy_with_logits so that you don't have to convert your labels to a dense one-hot array. \n",
    "        neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits = fc3, labels = actions)\n",
    "        #loss = tf.nn.sparse_softmax_cross_entropy_with_logits (neg_log_prob * discounted_episode_rewards_)\n",
    "        loss = tf.reduce_mean(neg_log_prob * discounted_episode_rewards_) \n",
    "        \n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "# Setup TensorBoard Writer\n",
    "\n",
    "\n",
    "## Losses\n",
    "## TRAINING Hyperparameters\n",
    "\n",
    "# tf.summary.scalar(\"Loss\", loss)\n",
    "\n",
    "# ## Reward mean\n",
    "# tf.summary.scalar(\"Reward_mean\", mean_reward_)\n",
    "\n",
    "max_episodes = 500\n",
    "\n",
    "gamma = 0.95 # Discount rate\n",
    "max_batch = NbStat*5\n",
    "    \n",
    "episode_rewards_sum = 0\n",
    "\n",
    "        # Launch the game\n",
    "    #state = env.reset()\n",
    "    #ne_state=np.identity(NbStat)[state:state+1]\n",
    "    #env.render()\n",
    "episode_length=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from pgpendul.ckpt\n",
      "None\n",
      "****************************************************\n",
      "EPISODE  0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[533 315  46  46]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[585 323  46  46]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[650 334  45  45]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[639 335  43  43]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  4\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[631 330  44  44]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  5\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[564 336  42  42]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  6\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[547 328  42  42]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  7\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[536 326  44  44]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  8\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[558 332  40  40]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  9\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[544 293  66 132]]\n",
      "state 0 ne_state 3472 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[545 330  44  44]]\n",
      "state 3472 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  10\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[598 314  47  47]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  11\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[603 314  49  49]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  12\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[645 323  44  44]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  13\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[660 321  44  44]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  14\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[624 276  72 144]]\n",
      "state 0 ne_state 3256 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[648 319  45  45]]\n",
      "state 3256 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  15\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[691 335  44  44]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  16\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[688 329  44  44]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  17\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[704 324  44  44]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  18\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[722 268  76 151]]\n",
      "state 0 ne_state 3160 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[751 311  46  46]]\n",
      "state 3160 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  19\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[729 322  47  47]]\n",
      "state 0 ne_state 0 action 1\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  20\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[693 316  49  49]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  21\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[660 302  51  51]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  22\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[666 303  50  50]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  23\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[672 303  52  52]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  24\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[654 277  53  53]]\n",
      "state 0 ne_state 3262 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[655 281  54  54]]\n",
      "state 3262 ne_state 3379 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[665 281  53  53]]\n",
      "state 3379 ne_state 3381 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[674 291  52  52]]\n",
      "state 3381 ne_state 3498 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[730 313  48  48]]\n",
      "state 3498 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  25\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[ 19 609  69  69]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  26\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[252 555  44  44]\n",
      " [248 603  45  45]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  27\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[608 314  46  46]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 0\n",
      "****************************************************\n",
      "EPISODE  28\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[379 301  51  51]]\n",
      "state 0 ne_state 3555 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[413 274  52  52]]\n",
      "state 3555 ne_state 3214 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[396 271  55  55]]\n",
      "state 3214 ne_state 3211 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[368 258  55  55]]\n",
      "state 3211 ne_state 2973 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[331 244  58  58]]\n",
      "state 2973 ne_state 2850 action 3\n",
      "Score 1\n",
      "****************************************************\n",
      "EPISODE  29\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[428 230  31  63]]\n",
      "state 0 ne_state 2753 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[389 194  32  64]]\n",
      "state 2753 ne_state 2281 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[344 120  41  81]\n",
      " [341 211  35  71]]\n",
      "state 2281 ne_state 1460 action 3\n",
      "Score 2\n",
      "****************************************************\n",
      "EPISODE  30\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[123  64  84  84]]\n",
      "state 0 ne_state 720 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[102  37  84  84]\n",
      " [198 324  63  63]]\n",
      "state 720 ne_state 368 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[121  37  84  84]]\n",
      "state 368 ne_state 372 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[421 146  38  76]\n",
      " [416 222  40  80]]\n",
      "state 372 ne_state 1708 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[325 139  74  74]\n",
      " [425 378  56  56]\n",
      " [396 406  56  56]]\n",
      "state 1708 ne_state 1573 action 0\n",
      "Score 3\n",
      "****************************************************\n",
      "EPISODE  31\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[318 111  77  77]\n",
      " [428 366  58  58]]\n",
      "state 0 ne_state 1339 action 3\n",
      "Score 4\n",
      "****************************************************\n",
      "EPISODE  32\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[325 114  77  77]\n",
      " [398 392  66  66]]\n",
      "state 0 ne_state 1341 action 2\n",
      "Score 5\n",
      "****************************************************\n",
      "EPISODE  33\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[320 105  78  78]]\n",
      "state 0 ne_state 1224 action 3\n",
      "Score 6\n",
      "****************************************************\n",
      "EPISODE  34\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[268  18  89  89]]\n",
      "state 0 ne_state 169 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[506 495  55 110]]\n",
      "state 169 ne_state 0 action 2\n",
      "Score 6\n",
      "****************************************************\n",
      "EPISODE  35\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[360  81  82  82]]\n",
      "state 0 ne_state 1000 action 2\n",
      "Score 7\n",
      "****************************************************\n",
      "EPISODE  36\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[588 198  42  84]]\n",
      "state 0 ne_state 2321 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 2321 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[409 311  92  92]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 7\n",
      "****************************************************\n",
      "EPISODE  37\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[607 461  76 151]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 7\n",
      "****************************************************\n",
      "EPISODE  38\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[638  23  34  67]]\n",
      "state 0 ne_state 359 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 359 ne_state 0 action 2\n",
      "****************************************************\n",
      "EPISODE  39\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[598 501  60 120]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 7\n",
      "****************************************************\n",
      "EPISODE  40\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[584  35  55 110]\n",
      " [582 468  66 132]]\n",
      "state 0 ne_state 464 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[364 284 111 111]]\n",
      "state 464 ne_state 3320 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 3320 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[575  31  35  70]]\n",
      "state 0 ne_state 463 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[516 432  96 190]]\n",
      "state 463 ne_state 0 action 3\n",
      "Score 7\n",
      "****************************************************\n",
      "EPISODE  41\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[452 426 145 290]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 7\n",
      "****************************************************\n",
      "EPISODE  42\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[270 152 171 171]]\n",
      "state 0 ne_state 1794 action 2\n",
      "Score 8\n",
      "****************************************************\n",
      "EPISODE  43\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "****************************************************\n",
      "EPISODE  44\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[ 32 173  82  82]]\n",
      "state 0 ne_state 1978 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 1978 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[741  47  36  73]]\n",
      "state 0 ne_state 612 action 1\n",
      "****************************************************\n",
      "EPISODE  45\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[176   3 124 124]]\n",
      "state 0 ne_state 35 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 35 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "****************************************************\n",
      "EPISODE  46\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[452 209  75  75]]\n",
      "state 0 ne_state 2410 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 2410 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[371  38 149 149]]\n",
      "state 0 ne_state 422 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 422 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[686 458  80 158]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 8\n",
      "****************************************************\n",
      "EPISODE  47\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[403  19  90  90]\n",
      " [503 350  85  85]]\n",
      "state 0 ne_state 196 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[663  31  28  56]]\n",
      "state 196 ne_state 480 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 480 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "****************************************************\n",
      "EPISODE  48\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[742  84  35  70]]\n",
      "state 0 ne_state 1076 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[769 162  29  58]]\n",
      "state 1076 ne_state 2009 action 2\n",
      "Score 9\n",
      "****************************************************\n",
      "EPISODE  49\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[382  48  84  84]]\n",
      "state 0 ne_state 540 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 540 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[576 469  76 151]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 9\n",
      "****************************************************\n",
      "EPISODE  50\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[640 424 114 229]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 9\n",
      "****************************************************\n",
      "EPISODE  51\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[722  87  35  70]]\n",
      "state 0 ne_state 1072 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[748  85  37  74]]\n",
      "state 1072 ne_state 1077 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 1077 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "****************************************************\n",
      "EPISODE  52\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[319  30 154 154]]\n",
      "state 0 ne_state 411 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 411 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "****************************************************\n",
      "EPISODE  53\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[60 58 85 85]]\n",
      "state 0 ne_state 592 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[477 217  29  58]]\n",
      "state 592 ne_state 2531 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[406 256  58  58]]\n",
      "state 2531 ne_state 2981 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[554 278  54  54]]\n",
      "state 2981 ne_state 3242 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[559 280  54  54]]\n",
      "state 3242 ne_state 3359 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[624 290  53  53]]\n",
      "state 3359 ne_state 3488 action 2\n",
      "****************************************************\n",
      "EPISODE  54\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[713 299  52  52]]\n",
      "state 0 ne_state 3506 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[721 293  53  53]]\n",
      "state 3506 ne_state 3508 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[704 300  52  52]]\n",
      "state 3508 ne_state 0 action 2\n",
      "Score 9\n",
      "****************************************************\n",
      "EPISODE  55\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[708 295  52  52]]\n",
      "state 0 ne_state 3505 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[729 279  54  54]]\n",
      "state 3505 ne_state 3277 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[749 260  50  50]]\n",
      "state 3277 ne_state 3165 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[749 262  51  51]]\n",
      "state 3165 ne_state 3165 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[740 269  54  54]]\n",
      "state 3165 ne_state 3164 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[734 269  55  55]]\n",
      "state 3164 ne_state 3162 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[738 259  56  56]]\n",
      "state 3162 ne_state 3047 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[699 235  60  60]]\n",
      "state 3047 ne_state 2807 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[708 202  64  64]]\n",
      "state 2807 ne_state 2461 action 3\n",
      "[[0.0741785  0.09599086 0.43143332 0.39839736]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[721 204  65  65]]\n",
      "state 2461 ne_state 2464 action 2\n",
      "****************************************************\n",
      "EPISODE  56\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[749 245  51  51]]\n",
      "state 0 ne_state 2933 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 2933 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[  4 593  94 187]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 9\n",
      "****************************************************\n",
      "EPISODE  57\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[ 81 561  31  31]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 9\n",
      "****************************************************\n",
      "EPISODE  58\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[124 610  36  36]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 9\n",
      "****************************************************\n",
      "EPISODE  59\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[252 130  55  55]]\n",
      "state 0 ne_state 1558 action 3\n",
      "Score 10\n",
      "****************************************************\n",
      "EPISODE  60\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[215  86  60  60]]\n",
      "state 0 ne_state 971 action 3\n",
      "Score 11\n",
      "****************************************************\n",
      "EPISODE  61\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[  3 613  57  57]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 11\n",
      "****************************************************\n",
      "EPISODE  62\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[ 35 520  82  82]\n",
      " [ 38 459  72  72]\n",
      " [ 49 679  82  82]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 11\n",
      "****************************************************\n",
      "EPISODE  63\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[311 130  60  60]]\n",
      "state 0 ne_state 1570 action 0\n",
      "Score 12\n",
      "****************************************************\n",
      "EPISODE  64\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[400  24  52  52]\n",
      " [218 698  50  50]]\n",
      "state 0 ne_state 312 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[408  30  51  51]]\n",
      "state 312 ne_state 429 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 429 ne_state 0 action 0\n",
      "****************************************************\n",
      "EPISODE  65\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[599 661  67  67]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 12\n",
      "****************************************************\n",
      "EPISODE  66\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[598  41 114 114]]\n",
      "state 0 ne_state 583 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[353  97 134 134]]\n",
      "state 583 ne_state 1114 action 3\n",
      "Score 13\n",
      "****************************************************\n",
      "EPISODE  67\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[389  13 144 144]]\n",
      "state 0 ne_state 193 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[363 122 120 120]]\n",
      "state 193 ne_state 1464 action 2\n",
      "Score 14\n",
      "****************************************************\n",
      "EPISODE  68\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[485 185 107 107]]\n",
      "state 0 ne_state 2185 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[521 173 111 111]]\n",
      "state 2185 ne_state 2076 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[539 184 105 105]]\n",
      "state 2076 ne_state 2195 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[557 242  89  89]]\n",
      "state 2195 ne_state 2895 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[420 213 100 100]]\n",
      "state 2895 ne_state 2520 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[442 194  97  97]]\n",
      "state 2520 ne_state 2292 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 2292 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[636 644 103 103]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 14\n",
      "****************************************************\n",
      "EPISODE  69\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[710 148  85  85]]\n",
      "state 0 ne_state 1766 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[698 162  95  95]]\n",
      "state 1766 ne_state 1995 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[691 166  99  99]]\n",
      "state 1995 ne_state 1994 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 1994 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "****************************************************\n",
      "EPISODE  70\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[487 114 110 110]]\n",
      "state 0 ne_state 1373 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 1373 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[643 206  79  79]]\n",
      "state 0 ne_state 2448 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 2448 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "****************************************************\n",
      "EPISODE  71\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[144 710  50  50]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 14\n",
      "****************************************************\n",
      "EPISODE  72\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[254 717  60  60]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 14\n",
      "****************************************************\n",
      "EPISODE  73\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[664 231  88  88]]\n",
      "state 0 ne_state 2800 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[726 258  72  72]]\n",
      "state 2800 ne_state 3045 action 2\n",
      "****************************************************\n",
      "EPISODE  74\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[519 294  76  76]]\n",
      "state 0 ne_state 3467 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[470 293  73  73]]\n",
      "state 3467 ne_state 3458 action 1\n",
      "[[0.07303305 0.09875578 0.429365   0.39884618]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[403 271  79  79]]\n",
      "state 3458 ne_state 3212 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[268 202  99  99]]\n",
      "state 3212 ne_state 2373 action 3\n",
      "Score 15\n",
      "****************************************************\n",
      "EPISODE  75\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[302 215  83  83]]\n",
      "state 0 ne_state 2496 action 2\n",
      "Score 16\n",
      "****************************************************\n",
      "EPISODE  76\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[321 231  85  85]]\n",
      "state 0 ne_state 2732 action 1\n",
      "Score 17\n",
      "****************************************************\n",
      "EPISODE  77\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[351 256  74  74]]\n",
      "state 0 ne_state 2970 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[367 268  72  72]]\n",
      "state 2970 ne_state 3089 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[352 247  84  84]]\n",
      "state 3089 ne_state 2854 action 3\n",
      "Score 18\n",
      "****************************************************\n",
      "EPISODE  78\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[315 230  83  83]]\n",
      "state 0 ne_state 2731 action 1\n",
      "Score 19\n",
      "****************************************************\n",
      "EPISODE  79\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[368 252  82  82]]\n",
      "state 0 ne_state 2973 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[377 269  79  79]]\n",
      "state 2973 ne_state 3091 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[126 464 151 302]]\n",
      "state 3091 ne_state 0 action 2\n",
      "Score 19\n",
      "****************************************************\n",
      "EPISODE  80\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[456 284  70  70]]\n",
      "state 0 ne_state 3339 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[454 282  73  73]]\n",
      "state 3339 ne_state 3338 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[455 266  78  78]]\n",
      "state 3338 ne_state 3107 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[461 264  80  80]]\n",
      "state 3107 ne_state 3108 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[ 29 440 162 324]]\n",
      "state 3108 ne_state 0 action 3\n",
      "Score 19\n",
      "****************************************************\n",
      "EPISODE  81\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[466 210  87  87]]\n",
      "state 0 ne_state 2529 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[491 148  97  97]]\n",
      "state 2529 ne_state 1722 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[487 152  97  97]]\n",
      "state 1722 ne_state 1837 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[499 214  83  83]]\n",
      "state 1837 ne_state 2535 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[503 217  85  85]]\n",
      "state 2535 ne_state 2536 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[515 228  84  84]]\n",
      "state 2536 ne_state 2655 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[522 265  76  76]]\n",
      "state 2655 ne_state 3120 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[503 300  71  71]]\n",
      "state 3120 ne_state 3580 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[536 280  76  76]]\n",
      "state 3580 ne_state 3355 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[556 249  81  81]\n",
      " [450 356  76  76]]\n",
      "state 3355 ne_state 2895 action 3\n",
      "****************************************************\n",
      "EPISODE  82\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[578 118 115 115]]\n",
      "state 0 ne_state 1391 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[597  76 117 117]]\n",
      "state 1391 ne_state 931 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[592  74 115 115]]\n",
      "state 931 ne_state 930 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[551  13 136 136]]\n",
      "state 930 ne_state 226 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 226 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "****************************************************\n",
      "EPISODE  83\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "****************************************************\n",
      "EPISODE  84\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[410 167 101 101]]\n",
      "state 0 ne_state 1938 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[457 201  93  93]]\n",
      "state 1938 ne_state 2411 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[513 232  93  93]]\n",
      "state 2411 ne_state 2770 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[574 251  90  90]]\n",
      "state 2770 ne_state 3014 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[614 247  93  93]]\n",
      "state 3014 ne_state 2906 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 2906 ne_state 0 action 3\n",
      "****************************************************\n",
      "EPISODE  85\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[694 126 103 103]]\n",
      "state 0 ne_state 1530 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[687 126 105 105]]\n",
      "state 1530 ne_state 1529 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[626 444  46  92]]\n",
      "state 1529 ne_state 0 action 3\n",
      "Score 19\n",
      "****************************************************\n",
      "EPISODE  86\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[697 424  52 105]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 19\n",
      "****************************************************\n",
      "EPISODE  87\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "state 0 ne_state 0 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[235 724  62  62]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 19\n",
      "****************************************************\n",
      "EPISODE  88\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "state 0 ne_state 0 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "****************************************************\n",
      "EPISODE  89\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "state 0 ne_state 0 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "state 0 ne_state 0 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[ 67  75 108 108]]\n",
      "state 0 ne_state 825 action 0\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[136 139  88  88]]\n",
      "state 825 ne_state 1535 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[218 202  78  78]]\n",
      "state 1535 ne_state 2363 action 2\n",
      "Score 20\n",
      "****************************************************\n",
      "EPISODE  90\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[321 260  63  63]]\n",
      "state 0 ne_state 3080 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[322 252  68  68]]\n",
      "state 3080 ne_state 2964 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[258 229  74  74]]\n",
      "state 2964 ne_state 2603 action 1\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  91\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[237 250  70  70]]\n",
      "state 0 ne_state 2947 action 1\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[253 269  69  69]]\n",
      "state 2947 ne_state 3066 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[299 306  65  65]]\n",
      "state 3066 ne_state 3539 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': -0.2, 'x': -0.2, 'z': -0.2}}\n",
      "[[292 312  54  54]]\n",
      "state 3539 ne_state 0 action 1\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  92\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[255 290  60  60]]\n",
      "state 0 ne_state 3415 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[249 306  62  62]]\n",
      "state 3415 ne_state 3529 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[262 324  56  56]]\n",
      "state 3529 ne_state 0 action 2\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  93\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[324 351  53  53]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  94\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'angular': {'y': 0.2, 'x': 0.2, 'z': 0.2}}\n",
      "[[350 359  54  54]]\n",
      "state 0 ne_state 0 action 0\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  95\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[341 343  56  56]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  96\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[339 347  56  56]]\n",
      "state 0 ne_state 0 action 2\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  97\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[355 352  57  57]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  98\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[393 327  60  60]]\n",
      "state 0 ne_state 0 action 3\n",
      "Score 21\n",
      "****************************************************\n",
      "EPISODE  99\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': 0.5}}\n",
      "[[398 298  66  66]]\n",
      "state 0 ne_state 3443 action 3\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[399 296  70  70]]\n",
      "state 3443 ne_state 3443 action 2\n",
      "[[0.07298414 0.1000903  0.42389956 0.40302595]]\n",
      "{'linear': {'x': -0.5}}\n",
      "[[396 321  65  65]]\n",
      "state 3443 ne_state 0 action 2\n",
      "Score 21\n",
      "Score over time:  21\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "client.run() # This run the main loop of ROS\n",
    "teresa_controller = Teresa(client) # Robot API\n",
    "env = RobotEnv(teresa_controller, client) # Training Environment\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "        # Load the model\n",
    "    print(saver.restore(sess, \"pgpendul.ckpt\"))\n",
    "    # if not saver.restore(sess, \"pgpendul.ckpt\"):\n",
    "    #     print()\n",
    "    total_rewards = 0\n",
    "    rewards = []\n",
    "\n",
    "    for episode in range(100):\n",
    "        state = env.reset()\n",
    "        #ne_state=np.identity(NbStat)[state:state+1]\n",
    "        step = 0\n",
    "        done = False\n",
    "        \n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "\n",
    "       \n",
    "        #while True:\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < 10:\n",
    "            j+=1\n",
    "            state=int(state)\n",
    "            ne_state=np.identity(NbStat)[state:state+1]\n",
    "            # Choose action a, remember WE'RE NOT IN A DETERMINISTIC ENVIRONMENT, WE'RE OUTPUT PROBABILITIES.\n",
    "            action_probability_distribution = sess.run(action_distribution, feed_dict={input_: ne_state.reshape([1,NbStat])})\n",
    "            print(action_probability_distribution)\n",
    "            action = np.random.choice(range(action_probability_distribution.shape[1]), p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
    "            #action = np.argmax(action_probability_distribution)\n",
    "            \n",
    "\n",
    "            # new_state, reward, done, info = env.step(int(action),True)\n",
    "            new_state, reward, done, info = env.step(int(action))\n",
    "            env.render()\n",
    "\n",
    "            print(\"state\",state,\"ne_state\",new_state,\"action\",action) \n",
    "            total_rewards += reward\n",
    "            if done:    \n",
    "                rewards.append(total_rewards)\n",
    "                print (\"Score\", total_rewards)\n",
    "                break\n",
    "            state = new_state\n",
    "    env.close()\n",
    "print (\"Score over time: \" ,  total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the rewards according to the episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "robot_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
